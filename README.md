# üì∞ An√°lise textual de resumos de not√≠cias

Este reposit√≥rio cont√©m o c√≥digo e o relat√≥rio final do projeto "An√°lise Textual de Resumo de Not√≠cias", realizado como parte da disciplina **Introdu√ß√£o ao Aprendizado de M√°quina (2024/1)** no Instituto de Computa√ß√£o da Universidade Federal do Rio de Janeiro <a href="https://ufrj.br/" target="blank">(UFRJ)</a>.

## üéØ Objetivo

O projeto visa a classifica√ß√£o de resumos de not√≠cias de acordo com seus temas, utilizando t√©cnicas de vetoriza√ß√£o de textos e algoritmos de aprendizado de m√°quina. A partir disso, foi realizada a compara√ß√£o entre os modelos de **Regress√£o Log√≠stica** e **Floresta Aleat√≥ria** para determinar qual algoritmo apresenta melhor desempenho na tarefa de classifica√ß√£o.

## üóÑÔ∏è Base de Dados

Os dados utilizados foram extra√≠dos do [News Category Dataset](https://www.kaggle.com/rmisra/news-category-dataset), que cont√©m mais de 200 mil manchetes e resumos de not√≠cias publicadas entre 2012 e 2022 no [HuffPost](https://www.huffpost.com/).

Os atributos principais utilizados no projeto foram:

- **headline**: t√≠tulo da not√≠cia
- **short description**: resumo da not√≠cia
- **category**: categoria da not√≠cia (vari√°vel alvo)

## üõ†Ô∏è Pr√©-processamento

As etapas de pr√©-processamento incluem:

1. **Tokeniza√ß√£o**: Segmenta√ß√£o do texto em palavras.
2. **Remo√ß√£o de caracteres n√£o-alfab√©ticos**: Exclus√£o de n√∫meros e pontua√ß√µes.
3. **Remo√ß√£o de stop-words**: Exclus√£o de palavras irrelevantes (como artigos e pronomes).
4. **Stemming**: Redu√ß√£o das palavras √†s suas ra√≠zes.
5. **Vetoriza√ß√£o**: Convers√£o dos textos em vetores utilizando a t√©cnica de **TF-IDF**.

## üìä Modelos Utilizados

1. **Regress√£o Log√≠stica**: Um modelo linear simples e eficiente para a classifica√ß√£o multiclasse.
2. **Floresta Aleat√≥ria**: Um ensemble de √°rvores de decis√£o, conhecido pela sua robustez e capacidade de interpretar a import√¢ncia dos atributos.

Ambos os modelos foram otimizados utilizando a t√©cnica de **Grid Search** para encontrar os melhores hiperpar√¢metros.

## üìà Resultados

- **Regress√£o Log√≠stica**: 
  - Acur√°cia de teste: 92%
  - F1-Score (Macro): 0.87
  - Melhor desempenho geral para a tarefa de classifica√ß√£o.

- **Floresta Aleat√≥ria**:
  - Acur√°cia de teste: 84%
  - F1-Score (Macro): 0.83
  - Apresentou maior interpretabilidade, mas desempenho inferior √† regress√£o log√≠stica.

## üèÅ Conclus√£o

A **Regress√£o Log√≠stica** demonstrou ser um modelo eficiente para a tarefa de classifica√ß√£o de textos, apresentando uma acur√°cia maior em compara√ß√£o √† Floresta Aleat√≥ria. Al√©m disso, o projeto evidenciou a import√¢ncia do pr√©-processamento dos dados e da escolha adequada de modelos de aprendizado para tarefas de classifica√ß√£o textual.

## üîó Refer√™ncias

Avikumart (2022). [nlp] news articles classif (wordembeddings&rnn). Acessado em: 2024-06-13.

Heng (2018). News category classifier (val acc 0.65). Acessado em: 2024-06-13.

Manning, C. D. (2008). Introduction to information retrieval. Syngress Publishing,. Cap√≠tulos 1, 2, 6 e 8.

Misra, R. (2022). News category dataset. arXiv preprint arXiv:2209.11429.

Misra, R. and Grover, J. (2021). Sculpting Data for ML: The first act of Machine Learning.
